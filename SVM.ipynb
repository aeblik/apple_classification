{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(features_file, output_folder):\n",
    "    # Ensure the input file and output directory exist\n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"File not found: {features_file}\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(features_file)\n",
    "    X = df.drop(columns=[\"Tree\", \"Apple\", \"Variety\", \"Augmented\", \"Mean_Color_0\", \"Mean_Color_1\", \"Mean_Color_2\", \"Std_Color_0\", \"Std_Color_1\", \"Std_Color_2\", \"Color_Range_0\", \"Color_Range_1\", \"Color_Range_2\"])\n",
    "    y = df[\"Variety\"]\n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.3, stratify=y_train_full, random_state=42\n",
    "    )  # Validation set is 20% of training data\n",
    "\n",
    "    # SVM hyperparameter grid\n",
    "    param_grid = {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 20, 30, 40, 50, 100, 200, 400,600, 800, 1000],\n",
    "        \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV with Cross-Validation on Training Data\n",
    "    grid_search = GridSearchCV(\n",
    "        SVC(random_state=42, probability=True),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    y_val_pred = best_svm.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Cross-Validation Score\n",
    "    cross_val_scores = cross_val_score(best_svm, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    cross_val_mean = np.mean(cross_val_scores)\n",
    "    cross_val_std = np.std(cross_val_scores)\n",
    "    print(f\"Cross-Validation Accuracy: Mean = {cross_val_mean}, Std = {cross_val_std}\")\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    y_test_pred = best_svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    classification_report_str = classification_report(y_test, y_test_pred, output_dict=False)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Test Precision: {precision:.3f}\")\n",
    "    print(f\"Test Recall: {recall:.3f}\")\n",
    "    print(f\"Test F1 Score: {f1:.3f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "\n",
    "    # Save results\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_file = f\"{output_folder}/random_forest_results.csv\"\n",
    "    results.to_csv(results_file, index=False)\n",
    "\n",
    "    # Generate plots\n",
    "    plot_confusion_matrix(y_test, y_test_pred, output_folder)\n",
    "    plot_svm_metrics(accuracy, precision, recall, f1, output_folder)\n",
    "    plot_svm_hyperparameter_results(grid_search.cv_results_, output_folder)\n",
    "    plot_roc_curves_combined(best_svm, X_test, y_test, y.unique(), output_folder)\n",
    "\n",
    "    print(f\"All SVM metrics and visualizations saved to {output_folder}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_test_pred, output_folder):\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.title(\"SVM Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_folder}/svm_confusion_matrix.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_svm_metrics(accuracy, precision, recall, f1, output_folder):\n",
    "    metrics = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1}\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(metrics.keys(), metrics.values(), color=\"skyblue\")\n",
    "    plt.title(\"SVM Metrics\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(f\"{output_folder}/svm_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_svm_hyperparameter_results(cv_results, output_folder):\n",
    "    results = pd.DataFrame(cv_results)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for kernel in results[\"param_kernel\"].unique():\n",
    "        kernel_data = results[results[\"param_kernel\"] == kernel]\n",
    "        plt.plot(kernel_data[\"param_C\"], kernel_data[\"mean_test_score\"], label=kernel, marker=\"o\", linestyle=\"-\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"C\")\n",
    "    plt.ylabel(\"Mean Test Accuracy\")\n",
    "    plt.title(\"SVM Accuracy vs. Hyperparameters\")\n",
    "    plt.legend(title=\"Kernel\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{output_folder}/svm_accuracy_vs_hyperparameters.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_roc_curves_combined(model, X_test, y_test, class_names, output_folder):\n",
    "    y_test_binarized = label_binarize(y_test, classes=class_names)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    roc_data = []\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_data.append((class_name, fpr, tpr, roc_auc))\n",
    "\n",
    "    roc_data_sorted = sorted(roc_data, key=lambda x: x[3], reverse=True)\n",
    "    best_roc_data = roc_data_sorted[:5]\n",
    "    worst_roc_data = roc_data_sorted[-5:]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for class_name, fpr, tpr, roc_auc in best_roc_data:\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"Top 5: {class_name} (AUC = {roc_auc:.2f})\")\n",
    "    for class_name, fpr, tpr, roc_auc in worst_roc_data:\n",
    "        plt.plot(fpr, tpr, lw=2, linestyle=\"--\", label=f\"Worst 5: {class_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=2, label=\"Random Classifier\")\n",
    "    plt.title(\"Top 5 and Worst 5 ROC Curves\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"best\", fontsize=\"small\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_folder}/svm_top_and_worst_roc_curves.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 200, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Validation Accuracy: 0.9321789321789322\n",
      "Cross-Validation Accuracy: Mean = 0.8726044413866912, Std = 0.010947237302930683\n",
      "Test Accuracy: 0.926\n",
      "Test Precision: 0.929\n",
      "Test Recall: 0.926\n",
      "Test F1 Score: 0.925\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " 14-001-1296       0.93      0.90      0.92        30\n",
      " 14-001-1300       0.94      1.00      0.97        30\n",
      " 14-001-1353       0.94      0.97      0.95        30\n",
      " 14-001-1496       0.93      0.90      0.92        30\n",
      " 14-001-1504       0.91      1.00      0.95        30\n",
      " 14-001-1516       0.94      1.00      0.97        30\n",
      " 14-001-1529       1.00      1.00      1.00        30\n",
      " 14-001-1572       0.88      0.77      0.82        30\n",
      " 14-001-1579       0.88      0.97      0.92        30\n",
      " 14-001-1873       0.90      0.87      0.88        30\n",
      " 14-001-1878       1.00      0.87      0.93        30\n",
      " 14-001-1953       1.00      1.00      1.00        30\n",
      " 14-001-2042       0.74      0.93      0.82        30\n",
      " 14-001-2103       0.91      0.97      0.94        30\n",
      " 14-001-2266       0.97      1.00      0.98        30\n",
      " 14-001-2526       0.88      1.00      0.94        30\n",
      " 14-001-2551       0.97      1.00      0.98        30\n",
      " 14-001-2640       1.00      1.00      1.00        30\n",
      " 14-001-2651       0.93      0.90      0.92        30\n",
      " 14-001-2748       0.85      0.93      0.89        30\n",
      " 14-001-2791       1.00      0.97      0.98        30\n",
      " 14-001-2860       0.88      0.73      0.80        30\n",
      " 14-001-3019       0.86      0.83      0.85        30\n",
      " 14-001-3232       0.96      0.90      0.93        30\n",
      " 14-001-3234       0.78      0.60      0.68        30\n",
      " 14-001-3239       1.00      0.93      0.97        30\n",
      " 14-001-3240       0.93      0.87      0.90        30\n",
      " 14-001-3244       1.00      0.93      0.97        30\n",
      " 14-001-3245       0.81      1.00      0.90        30\n",
      " 14-001-3247       0.97      0.97      0.97        30\n",
      "  14-001-358       1.00      0.97      0.98        30\n",
      "  14-001-458       1.00      0.93      0.97        30\n",
      "  14-001-846       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.93       990\n",
      "   macro avg       0.93      0.93      0.93       990\n",
      "weighted avg       0.93      0.93      0.93       990\n",
      "\n",
      "All SVM metrics and visualizations saved to C:/Daten/PA2/Code/Output/ModelComparison_1112_NoColor.\n"
     ]
    }
   ],
   "source": [
    "train_svm(\n",
    "        features_file=\"C:/Daten/PA2/Code/Output/apple_features_balanced_FE_Final_REVISED_1012.csv\",\n",
    "        output_folder=\"C:/Daten/PA2/Code/Output/ModelComparison_1112_NoColor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results WITHOUT Color:\n",
    "\n",
    "Best Parameters: {'C': 200, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "\n",
    "Validation Accuracy: 0.9321789321789322\n",
    "\n",
    "Cross-Validation Accuracy: Mean = 0.8726044413866912, Std = 0.010947237302930683\n",
    "\n",
    "Test Accuracy: 0.926\n",
    "\n",
    "Test Precision: 0.929\n",
    "\n",
    "Test Recall: 0.926\n",
    "\n",
    "Test F1 Score: 0.925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_color(features_file, output_folder):\n",
    "    # Ensure the input file and output directory exist\n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"File not found: {features_file}\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(features_file)\n",
    "    X = df.drop(columns=[\"Tree\", \"Apple\", \"Variety\", \"Augmented\"])\n",
    "    y = df[\"Variety\"]\n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.3, stratify=y_train_full, random_state=42\n",
    "    )  # Validation set is 20% of training data\n",
    "\n",
    "    # SVM hyperparameter grid\n",
    "    param_grid = {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 20, 30, 40, 50, 100, 200, 400,600, 800, 1000],\n",
    "        \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV with Cross-Validation on Training Data\n",
    "    grid_search = GridSearchCV(\n",
    "        SVC(random_state=42, probability=True),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    y_val_pred = best_svm.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Cross-Validation Score\n",
    "    cross_val_scores = cross_val_score(best_svm, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    cross_val_mean = np.mean(cross_val_scores)\n",
    "    cross_val_std = np.std(cross_val_scores)\n",
    "    print(f\"Cross-Validation Accuracy: Mean = {cross_val_mean}, Std = {cross_val_std}\")\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    y_test_pred = best_svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    classification_report_str = classification_report(y_test, y_test_pred, output_dict=False)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Test Precision: {precision:.3f}\")\n",
    "    print(f\"Test Recall: {recall:.3f}\")\n",
    "    print(f\"Test F1 Score: {f1:.3f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "\n",
    "    # Save results\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_file = f\"{output_folder}/random_forest_results.csv\"\n",
    "    results.to_csv(results_file, index=False)\n",
    "\n",
    "    # Generate plots\n",
    "    plot_confusion_matrix(y_test, y_test_pred, output_folder)\n",
    "    plot_svm_metrics(accuracy, precision, recall, f1, output_folder)\n",
    "    plot_svm_hyperparameter_results(grid_search.cv_results_, output_folder)\n",
    "    plot_roc_curves_combined(best_svm, X_test, y_test, y.unique(), output_folder)\n",
    "\n",
    "    print(f\"All SVM metrics and visualizations saved to {output_folder}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 20, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Validation Accuracy: 0.976911976911977\n",
      "Cross-Validation Accuracy: Mean = 0.9653690326032948, Std = 0.012287226178542632\n",
      "Test Accuracy: 0.983\n",
      "Test Precision: 0.984\n",
      "Test Recall: 0.983\n",
      "Test F1 Score: 0.983\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " 14-001-1296       1.00      0.90      0.95        30\n",
      " 14-001-1300       1.00      1.00      1.00        30\n",
      " 14-001-1353       0.97      1.00      0.98        30\n",
      " 14-001-1496       1.00      0.93      0.97        30\n",
      " 14-001-1504       0.94      1.00      0.97        30\n",
      " 14-001-1516       1.00      1.00      1.00        30\n",
      " 14-001-1529       1.00      1.00      1.00        30\n",
      " 14-001-1572       0.97      0.93      0.95        30\n",
      " 14-001-1579       0.94      1.00      0.97        30\n",
      " 14-001-1873       0.85      0.93      0.89        30\n",
      " 14-001-1878       1.00      0.87      0.93        30\n",
      " 14-001-1953       1.00      1.00      1.00        30\n",
      " 14-001-2042       1.00      1.00      1.00        30\n",
      " 14-001-2103       0.94      0.97      0.95        30\n",
      " 14-001-2266       1.00      1.00      1.00        30\n",
      " 14-001-2526       1.00      1.00      1.00        30\n",
      " 14-001-2551       1.00      1.00      1.00        30\n",
      " 14-001-2640       1.00      1.00      1.00        30\n",
      " 14-001-2651       1.00      1.00      1.00        30\n",
      " 14-001-2748       1.00      1.00      1.00        30\n",
      " 14-001-2791       1.00      1.00      1.00        30\n",
      " 14-001-2860       0.94      1.00      0.97        30\n",
      " 14-001-3019       0.97      1.00      0.98        30\n",
      " 14-001-3232       1.00      1.00      1.00        30\n",
      " 14-001-3234       1.00      0.97      0.98        30\n",
      " 14-001-3239       1.00      1.00      1.00        30\n",
      " 14-001-3240       1.00      0.97      0.98        30\n",
      " 14-001-3244       1.00      1.00      1.00        30\n",
      " 14-001-3245       1.00      1.00      1.00        30\n",
      " 14-001-3247       1.00      1.00      1.00        30\n",
      "  14-001-358       1.00      1.00      1.00        30\n",
      "  14-001-458       0.97      1.00      0.98        30\n",
      "  14-001-846       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.98       990\n",
      "   macro avg       0.98      0.98      0.98       990\n",
      "weighted avg       0.98      0.98      0.98       990\n",
      "\n",
      "All SVM metrics and visualizations saved to C:/Daten/PA2/Code/Output/ModelComparison_1112_WithColor.\n"
     ]
    }
   ],
   "source": [
    "train_svm_color(features_file=\"C:/Daten/PA2/Code/Output/apple_features_balanced_FE_Final_REVISED_1012.csv\",\n",
    "                output_folder=\"C:/Daten/PA2/Code/Output/ModelComparison_1112_WithColor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results WITH Color:\n",
    "\n",
    "Best Parameters: {'C': 20, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "\n",
    "Validation Accuracy: 0.976911976911977\n",
    "\n",
    "Cross-Validation Accuracy: Mean = 0.9653690326032948, Std = 0.012287226178542632\n",
    "\n",
    "Test Accuracy: 0.983\n",
    "\n",
    "Test Precision: 0.984\n",
    "\n",
    "Test Recall: 0.983\n",
    "\n",
    "Test F1 Score: 0.983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
